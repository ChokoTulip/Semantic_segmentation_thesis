{"cells":[{"cell_type":"code","source":["####################################################\n","# Variables in this cell shall be assigned by user #\n","####################################################\n","\n","# MODEL - name of the neural network architecture to be used\n","#       - Segnet or Xunet\n","# WORKING_DIR - folder where the unlabeled data will be processed and results will be found\n","# IMAGES_DIR  - folder where images to be processed can be found (doesn't have to be in working dir)\n","# WEIGHTS     - file containing pre-trained weights of neural network (-||-)\n","#\n","# OUTPUT_COLLAPSED_CARD     - set to True if crumbled cells should be processed and cropped out as well\n","# OUTPUT_HALFCOLLAPSED_CARD - set to True if half-crumbled cells should be processed and cropped out as well\n","\n","MODEL = 'Segnet'  # Segnet or Xunet\n","\n","WORKING_DIR = '/content/drive/MyDrive/Colab Notebooks/FinalSeg/'\n","IMAGES_DIR = WORKING_DIR + 'Images/'\n","WEIGHTS = WORKING_DIR + 'pretrained_weights/segnet_aug.h5'\n","\n","OUTPUT_HALFCOLLAPSED_CARD = False # True or False"],"metadata":{"id":"kU-_DAAqn1d1","executionInfo":{"status":"ok","timestamp":1646922755695,"user_tz":-60,"elapsed":12,"user":{"displayName":"Filip Kadlec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03444318018645607943"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10996,"status":"ok","timestamp":1646922766682,"user":{"displayName":"Filip Kadlec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03444318018645607943"},"user_tz":-60},"id":"Qg-epmkPZPI7","outputId":"bcb92b46-a23f-488d-af89-b79ff1cc3074"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: image_slicer in /usr/local/lib/python3.7/dist-packages (2.1.1)\n","Requirement already satisfied: Pillow==7.2.0 in /usr/local/lib/python3.7/dist-packages (from image_slicer) (7.2.0)\n"]}],"source":["###################################\n","#  Importing necessary libraries  #\n","###################################\n","\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","import os\n","import imageio\n","import cv2\n","import shutil\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","%pip install image_slicer\n","from image_slicer import slice, save_tiles\n","from scipy.ndimage import binary_closing\n","\n","import tensorflow as tf\n","from tensorflow.keras.utils import normalize\n","from keras.models import Model\n","from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, \\\n","    Dropout, Lambda, ZeroPadding2D, LeakyReLU\n","from keras.applications.xception import Xception"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"7lK6Kk7zloJa","executionInfo":{"status":"ok","timestamp":1646922767517,"user_tz":-60,"elapsed":839,"user":{"displayName":"Filip Kadlec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03444318018645607943"}}},"outputs":[],"source":["###################################\n","# Definitions of custom functions #\n","###################################\n","\n","def load_images(orig_images_dir):\n","    path = orig_images_dir\n","    images = {}\n","    for filename in os.listdir(path):\n","        img = cv2.imread(os.path.join(path, filename))\n","        if img is not None:\n","            images[filename] = img\n","    return images\n","\n","def get_model():\n","    if MODEL is 'Segnet':\n","      return Segnet()\n","    elif MODEL is 'Xunet':\n","      return Unet_Xception_ResNetBlock()\n","    else:\n","      print(\"Non existant variable MODEL, default SeNet architecture was chosen instead.\")\n","      return Segnet()\n","\n","def Segnet(nClasses=4, input_height=512, input_width=512):\n","    inputs = Input(shape=(input_height, input_width, 1))\n","\n","    #Encoder\n","    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n","    conv1 = BatchNormalization()(conv1)\n","    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n","    conv1 = BatchNormalization()(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n","    conv2 = BatchNormalization()(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n","    conv3 = BatchNormalization()(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n","    conv4 = BatchNormalization()(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","    # Decode\n","    up7 = UpSampling2D(size=(2, 2))(pool4)\n","    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same')(up7)\n","    conv7 = BatchNormalization()(conv7)\n","    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv7)\n","    conv7 = BatchNormalization()(conv7)\n","\n","    up8 = UpSampling2D(size=(2, 2))(conv7)\n","    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same')(up8)\n","    conv8 = BatchNormalization()(conv8)\n","    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv8)\n","    conv8 = BatchNormalization()(conv8)\n","\n","    up9 = UpSampling2D(size=(2, 2))(conv8)\n","    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same')(up9)\n","    conv9 = BatchNormalization()(conv9)\n","    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv9)\n","    conv9 = BatchNormalization()(conv9)\n","\n","    up10 = UpSampling2D(size=(2, 2))(conv9)\n","    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same')(up10)\n","    conv10 = BatchNormalization()(conv10)\n","    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv10)\n","    conv10 = BatchNormalization()(conv10)\n","    outputs = Conv2D(nClasses, (1, 1), padding='same', activation='softmax')(conv10)\n","\n","    model = Model(inputs, outputs)\n","    \n","    return model\n","\n","\n","def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n","    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n","    x = BatchNormalization()(x)\n","    if activation == True:\n","        x = LeakyReLU(alpha=0.1)(x)\n","    return x\n","\n","def residual_block(blockInput, num_filters=16):\n","    x = LeakyReLU(alpha=0.1)(blockInput)\n","    x = BatchNormalization()(x)\n","    blockInput = BatchNormalization()(blockInput)\n","    x = convolution_block(x, num_filters, (3,3) )\n","    x = convolution_block(x, num_filters, (3,3), activation=False)\n","    x = Add()([x, blockInput])\n","    return x\n","\n","\n","def Unet_Xception_ResNetBlock(nClasses=4, input_height=512, input_width=512):\n","    \n","    backbone = Xception(input_shape=(input_height, input_width, 1), weights=None, include_top=False)\n","    \n","    inputs = backbone.input\n","\n","    conv4 = backbone.layers[121].output\n","    conv4 = LeakyReLU(alpha=0.1)(conv4)\n","    pool4 = MaxPooling2D((2, 2))(conv4)\n","    pool4 = Dropout(0.1)(pool4)\n","    \n","     # Middle\n","    convm = Conv2D(16*32, (3, 3), activation=None, padding=\"same\")(pool4)\n","    convm = residual_block(convm, 16*32)\n","    convm = residual_block(convm, 16*32)\n","    convm = LeakyReLU(alpha=0.1)(convm)\n","    \n","    # 8 -> 16\n","    deconv4 = Conv2DTranspose(16*16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n","    uconv4 = concatenate([deconv4, conv4])\n","    uconv4 = Dropout(0.1)(uconv4)\n","    \n","    uconv4 = Conv2D(16*16, (3, 3), activation=None, padding=\"same\")(uconv4)\n","    uconv4 = residual_block(uconv4, 16 * 16)\n","    uconv4 = residual_block(uconv4, 16*16)\n","    uconv4 = LeakyReLU(alpha=0.1)(uconv4)\n","    \n","    # 16 -> 32\n","    deconv3 = Conv2DTranspose(16*8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n","    conv3 = backbone.layers[31].output\n","    uconv3 = concatenate([deconv3, conv3])    \n","    uconv3 = Dropout(0.1)(uconv3)\n","    \n","    uconv3 = Conv2D(16*8, (3, 3), activation=None, padding=\"same\")(uconv3)\n","    uconv3 = residual_block(uconv3, 16*8)\n","    uconv3 = residual_block(uconv3, 16*8)\n","    uconv3 = LeakyReLU(alpha=0.1)(uconv3)\n","\n","    # 32 -> 64\n","    deconv2 = Conv2DTranspose(16*4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n","    conv2 = backbone.layers[21].output\n","    conv2 = ZeroPadding2D(((1,0),(1,0)))(conv2)\n","    uconv2 = concatenate([deconv2, conv2])\n","        \n","    uconv2 = Dropout(0.1)(uconv2)\n","    uconv2 = Conv2D(16*4, (3, 3), activation=None, padding=\"same\")(uconv2)\n","    uconv2 = residual_block(uconv2, 16*4)\n","    uconv2 = residual_block(uconv2, 16*4)\n","    uconv2 = LeakyReLU(alpha=0.1)(uconv2)\n","    \n","    # 64 -> 128\n","    deconv1 = Conv2DTranspose(16*2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n","    conv1 = backbone.layers[11].output\n","    conv1 = ZeroPadding2D(((3,0),(3,0)))(conv1)\n","    uconv1 = concatenate([deconv1, conv1])\n","    \n","    uconv1 = Dropout(0.1)(uconv1)\n","    uconv1 = Conv2D(16*2, (3, 3), activation=None, padding=\"same\")(uconv1)\n","    uconv1 = residual_block(uconv1, 16*2)\n","    uconv1 = residual_block(uconv1, 16*2)\n","    uconv1 = LeakyReLU(alpha=0.1)(uconv1)\n","    \n","    # 128 -> 256\n","    uconv0 = Conv2DTranspose(16*1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n","    uconv0 = Dropout(0.1)(uconv0)\n","    uconv0 = Conv2D(16*1, (3, 3), activation=None, padding=\"same\")(uconv0)\n","    uconv0 = residual_block(uconv0, 16*1)\n","    uconv0 = residual_block(uconv0, 16*1)\n","    uconv0 = LeakyReLU(alpha=0.1)(uconv0)\n","    \n","    uconv0 = Dropout(0.1/2)(uconv0)\n","\n","    outputs = Conv2D(nClasses, (1, 1), padding='same', activation='softmax')(uconv0)\n","    model = Model(inputs, outputs)\n","    return model"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"akuWIpLgAQ6b","executionInfo":{"status":"ok","timestamp":1646922793515,"user_tz":-60,"elapsed":26003,"user":{"displayName":"Filip Kadlec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03444318018645607943"}}},"outputs":[],"source":["############################################################ \n","# Load images, create temp cut dir, cut them into 64 tiles #\n","############################################################\n","\n","orig_images_dir = IMAGES_DIR\n","cut_images_dir = WORKING_DIR + 'TEMP_cut_images/'\n","if os.path.isdir(cut_images_dir):\n","    shutil.rmtree(cut_images_dir)\n","    os.mkdir(cut_images_dir)\n","else:\n","    os.mkdir(cut_images_dir)\n","\n","########### CHOOSE A SAMPLE IMG ###########\n","# orig_img = '210324_Sasa_Pavel_Image014_ch00.tif'\n","# orig_img = '201006b_Mouse_obj20zoom1_ch00.tif'\n","# orig_img = '210324_Sasa_Pavel_Image023_ch00.tif'\n","\n","# Get names of all original images from IMAGES_DIR folder\n","# and cut each of them into 64 tiles\n","list_of_origs = []\n","for f in os.listdir(IMAGES_DIR):\n","    if os.path.isfile(IMAGES_DIR+f) and (f.endswith(\".tif\") or f.endswith(\".png\")):\n","        list_of_origs.append(f)\n","        os.mkdir(cut_images_dir+f+'/')\n","        sliced_img = slice(IMAGES_DIR+f, 64, save=False)\n","        save_tiles(tiles=sliced_img, directory=cut_images_dir+f, prefix=f[:-4], format='png')\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AH85UlK8Y1FV","outputId":"93d2c276-9c9e-4242-a893-acca5bb8f2f8","executionInfo":{"status":"ok","timestamp":1646923042064,"user_tz":-60,"elapsed":248553,"user":{"displayName":"Filip Kadlec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03444318018645607943"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Segmenting 1th image:\n","\n","Segmented 64/64 tiles\n","Segmenting 2th image:\n","\n","Segmented 64/64 tiles\n","Segmenting 3th image:\n","\n","Segmented 64/64 tiles\n","Segmenting 4th image:\n","\n","Segmented 64/64 tiles\n","Segmenting 5th image:\n","\n","Segmented 64/64 tiles\n","Segmenting 6th image:\n","\n","Segmented 64/64 tiles\n","Segmenting 7th image:\n","\n","Segmented 64/64 tiles\n","Segmenting 8th image:\n","\n","Segmented 64/64 tiles\n","Segmenting 9th image:\n","\n","Segmented 64/64 tiles\n","Segmenting 10th image:\n","\n","Segmented 64/64 tiles"]}],"source":["################################################\n","# Load cut images, create segmaps folder, make #\n","# predictions with trained model, save segmaps #\n","################################################\n","predictions_dir = WORKING_DIR + 'TEMP_predictions/'\n","if os.path.isdir(predictions_dir):\n","    shutil.rmtree(predictions_dir)\n","    os.mkdir(predictions_dir)\n","else:\n","    os.mkdir(predictions_dir)\n","\n","model = get_model()\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[tf.keras.metrics.MeanIoU(num_classes=4)])\n","model.load_weights(WEIGHTS)\n","\n","# for the number of original images\n","for i in range(len(list_of_origs)):\n","    print(f'\\nSegmenting {i+1}th image:\\n')\n","    cut_images_dict = load_images(cut_images_dir+list_of_origs[i]+'/')\n","    os.mkdir(predictions_dir+list_of_origs[i]+ '/')\n","\n","# segment all 64 tiles of the original image\n","    counter = 1\n","    for img in cut_images_dict:\n","        current_image = cv2.imread(cut_images_dir+list_of_origs[i]+'/' + img,0)\n","        x_batch = []\n","        x_batch.append(current_image)\n","        x_batch = np.array(x_batch, np.float32) / 255.\n","\n","        x_batch = np.expand_dims(x_batch, axis=3)\n","        x_batch = normalize(x_batch, axis=1)\n","\n","        prediction = (model.predict(x_batch))\n","        predicted_img = np.argmax(prediction, axis=3)[0, :, :]\n","\n","        cv2.imwrite(predictions_dir + list_of_origs[i] + '/' + img, predicted_img)\n","        print(f'\\rSegmented {counter}/64 tiles', end='')\n","        counter += 1"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"5-DiJzAbrX6Q","executionInfo":{"status":"ok","timestamp":1646923052188,"user_tz":-60,"elapsed":10137,"user":{"displayName":"Filip Kadlec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03444318018645607943"}}},"outputs":[],"source":["################################################\n","# Join segmaps into final segmap of orig. dim. #\n","################################################\n","\n","results_dir = WORKING_DIR + 'RESULT/'\n","if os.path.isdir(results_dir):\n","    shutil.rmtree(results_dir)\n","    os.mkdir(results_dir)\n","else:\n","    os.mkdir(results_dir)\n","\n","for i in range(len(list_of_origs)):\n","    os.mkdir(results_dir+list_of_origs[i]+'/')\n","\n","    grid = Image.new('RGBA',size=(4096, 4096), color=(153, 153, 255))\n","    prediction_images_dict = load_images(predictions_dir+list_of_origs[i]+'/')\n","    horizontal = 0\n","    vertical = 0\n","    counter = 1\n","    for img in prediction_images_dict:\n","        curr_img = Image.open(predictions_dir + list_of_origs[i] + '/' + img)\n","        grid.paste(curr_img,box=(horizontal,vertical))\n","\n","        if counter%8 == 0:\n","            horizontal = 0\n","            vertical += 512\n","        else:\n","            horizontal += 512\n","\n","        counter += 1\n","\n","    mask_first_channel = grid.getchannel(0)\n","    mask_first_channel.save(results_dir+list_of_origs[i]+\"/final_mask.png\")"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"PwXdX-SQOaeC","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1pazs9guwHmiMtD1bkpmFNsCzpUPxT3A3"},"executionInfo":{"status":"ok","timestamp":1646923888453,"user_tz":-60,"elapsed":836275,"user":{"displayName":"Filip Kadlec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03444318018645607943"}},"outputId":"aa21abe6-f8ef-46ac-8dd6-b25c59319431"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["########################################\n","# Plot final segmap and original image #\n","########################################\n","\n","for i in range(len(list_of_origs)):\n","    finalplot_prediction = results_dir + list_of_origs[i] + '/final_mask.png'\n","    original_img = cv2.imread(IMAGES_DIR+list_of_origs[i],0)\n","\n","    prediction = imageio.imread(finalplot_prediction)\n","\n","    plt.figure(figsize=(32, 32))\n","    plt.subplot(231)\n","    plt.title('Original')\n","    plt.imshow(original_img[:, :], cmap='gray')\n","\n","    plt.subplot(232)\n","    plt.title('Prediction')\n","    plt.imshow(prediction[:, :], cmap='jet')\n","\n","    plt.savefig(results_dir + list_of_origs[i] + '/orig_and_pred.png', bbox_inches='tight')\n","    plt.show()\n","\n","\n","    ######################################################\n","    # Convert segmap into image, where cardiomyocytes    #\n","    # of interest have 1 and other pixels 0 (binary img) #\n","    ######################################################\n","    arr_prediction = np.asarray(prediction)\n","\n","    # val 2 is card. of interest\n","    pred_bin = np.zeros((4096,4096),dtype=np.int8)\n","    pred_bin_half = np.zeros((4096,4096),dtype=np.int8)\n","    for j in range(len(arr_prediction[1,:])):\n","        for k in range(len(arr_prediction[:,1])):\n","            if arr_prediction[j,k] == 2:\n","                pred_bin[j,k] = 1\n","                pred_bin_half[j,k] = 0\n","            elif arr_prediction[j,k] == 3:\n","                pred_bin[j,k] = 0\n","                pred_bin_half[j,k] = 1\n","            else:\n","                pred_bin[j,k] = 0\n","                pred_bin_half[j,k] = 0\n","\n","    ##############################################\n","    # Perform binary closing on binarized segmap #\n","    ##############################################\n","\n","    # print binary stuff\n","    # plt.imshow(data, interpolation='nearest')\n","    plt.figure(figsize=(8, 8))\n","    plt.imshow(pred_bin)\n","    plt.show()\n","    # perform CLOSING - Dilation followed by Erosion\n","    str_el = np.array([[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]], np.int8)\n","    closed_pred_bin = binary_closing(pred_bin, iterations=7, structure=str_el)\n","    # conversion from bool \"True, False\" to \"1, 0\"\n","    closed_pred_bin = 255*closed_pred_bin\n","\n","    # print closed binary stuff\n","    plt.figure(figsize=(8, 8))\n","    plt.imshow(closed_pred_bin)\n","    plt.show()\n","\n","    temp_bin_pred_img = results_dir + 'temp_bin_pred_img.png'\n","    cv2.imwrite(temp_bin_pred_img, closed_pred_bin)\n","    im = cv2.imread(temp_bin_pred_img, cv2.IMREAD_GRAYSCALE)\n","\n","    ##################################################\n","    # Find connected components and their properties.#\n","    # Then find bounding boxes and prepare for print #\n","    ##################################################\n","    \n","    conn_comp_output = cv2.connectedComponentsWithStats(im)\n","    # The first cell is the number of labels\n","    num_labels = conn_comp_output[0]\n","    # The second cell is the label matrix\n","    labels = conn_comp_output[1]\n","    # The third cell is the stat matrix \n","        # cv2.CC_STAT_LEFT The leftmost (x) coordinate which is the inclusive start of the bounding box in the horizontal direction.\n","        # cv2.CC_STAT_TOP The topmost (y) coordinate which is the inclusive start of the bounding box in the vertical direction.\n","        # cv2.CC_STAT_WIDTH The horizontal size of the bounding box\n","        # cv2.CC_STAT_HEIGHT The vertical size of the bounding box\n","        # cv2.CC_STAT_AREA The total area (in pixels) of the connected component\n","    stats = conn_comp_output[2]\n","    # The fourth cell is the centroid matrix\n","    centroids = conn_comp_output[3]\n","\n","    # select out the background\n","    max_area = 0\n","    max_area_index = 0\n","    for j in range(len(stats)):\n","        if stats[j][4] >= max_area:\n","            max_area = stats[j][4]\n","            max_area_index = j\n","\n","    # if area of conn comp is bigger than T (=10000) -> save bounding boxes\n","    saved_bb_x = []\n","    saved_bb_y = []\n","    saved_bb_x_width = []\n","    saved_bb_y_height = []\n","    area_thresh = 10000\n","    margin = 30\n","    for j in range(len(stats)):\n","        if (stats[j][4] >= area_thresh) and (j is not max_area_index):\n","            saved_bb_x.append(0 if ((stats[j][0]-margin)<0) else (stats[j][0]-margin))\n","            saved_bb_y.append(0 if ((stats[j][1]-margin)<0) else (stats[j][1]-margin))\n","            saved_bb_x_width.append(4096 if ((stats[j][2]+margin)>4096) else (stats[j][2]+margin))\n","            saved_bb_y_height.append(4096 if ((stats[j][3]+margin)>4096) else (stats[j][3]+margin))\n","\n","    ################################################\n","    # Print found bounding boxes over orig. image  #\n","    ################################################\n","\n","    plt.figure(figsize=(16, 16))\n","    im = cv2.imread(IMAGES_DIR + list_of_origs[i])\n","    for j in range(len(saved_bb_x)):\n","        cv2.rectangle(im, (saved_bb_x[j], saved_bb_y[j]), (saved_bb_x[j]+saved_bb_x_width[j], saved_bb_y[j]+saved_bb_y_height[j]), (255,70,0), 3)\n","    cv2.imwrite(results_dir + list_of_origs[i] + '/orig_with_BBs.png',im) \n","    implot = plt.imshow(im)\n","\n","    ##################################################################\n","    # Crop content of bounding boxes and save them to results folder #\n","    ##################################################################\n","\n","    cropped_results_dir = results_dir + list_of_origs[i] + '/crops/'\n","    os.mkdir(cropped_results_dir)\n","    orig_img_clean = cv2.imread(IMAGES_DIR+list_of_origs[i])\n","\n","    num = 1\n","    for j in range(len(saved_bb_x)):\n","        crop = orig_img_clean[saved_bb_y[j]:saved_bb_y[j]+saved_bb_y_height[j], saved_bb_x[j]:saved_bb_x[j]+saved_bb_x_width[j]]\n","        crop_name = f'crop_{num}.png'\n","        cv2.imwrite(cropped_results_dir + crop_name, crop)\n","        num += 1\n","\n","    if OUTPUT_HALFCOLLAPSED_CARD:\n","        closed_pred_bin_half = binary_closing(pred_bin_half, iterations=7, structure=str_el)\n","        closed_pred_bin_half = 255*closed_pred_bin_half\n","        temp_bin_pred_img_half = results_dir + 'temp_bin_pred_img_half.png'\n","        cv2.imwrite(temp_bin_pred_img_half, closed_pred_bin_half)\n","        im_half = cv2.imread(temp_bin_pred_img_half, cv2.IMREAD_GRAYSCALE)\n","        conn_comp_output_half = cv2.connectedComponentsWithStats(im_half)\n","        num_labels_half = conn_comp_output_half[0]\n","        labels_half = conn_comp_output_half[1]\n","        stats_half = conn_comp_output_half[2]\n","        centroids_half = conn_comp_output_half[3]\n","        max_area_half = 0\n","        max_area_index_half = 0\n","        for j in range(len(stats_half)):\n","            if stats_half[j][4] >= max_area_half:\n","                max_area_half = stats_half[j][4]\n","                max_area_index_half = j\n","        saved_bb_x_half = []\n","        saved_bb_y_half = []\n","        saved_bb_x_width_half = []\n","        saved_bb_y_height_half = []\n","        area_thresh_half = 10000\n","        margin_half = 50\n","        for j in range(len(stats_half)):\n","            if (stats_half[j][4] >= area_thresh_half) and (j is not max_area_index_half):\n","                saved_bb_x_half.append(0 if ((stats_half[j][0]-margin_half)<0) else (stats_half[j][0]-margin_half))\n","                saved_bb_y_half.append(0 if ((stats_half[j][1]-margin_half)<0) else (stats_half[j][1]-margin_half))\n","                saved_bb_x_width_half.append(4096 if ((stats_half[j][2]+margin_half)>4096) else (stats_half[j][2]+margin_half))\n","                saved_bb_y_height_half.append(4096 if ((stats_half[j][3]+margin_half)>4096) else (stats_half[j][3]+margin_half))\n","        \n","        im_half = cv2.imread(IMAGES_DIR + list_of_origs[i])\n","        for j in range(len(saved_bb_x_half)):\n","            cv2.rectangle(im_half, (saved_bb_x_half[j], saved_bb_y_half[j]), (saved_bb_x_half[j]+saved_bb_x_width_half[j], saved_bb_y_half[j]+saved_bb_y_height_half[j]), (255,70,0), 3)\n","        cv2.imwrite(results_dir + list_of_origs[i] + '/orig_with_halfcolapsed_BBs.png',im_half) \n","        implot = plt.imshow(im)\n","\n","        cropped_results_dir_half = results_dir + list_of_origs[i] + '/crops_halfcolapsed/'\n","        os.mkdir(cropped_results_dir_half)\n","        orig_img_clean_half = cv2.imread(IMAGES_DIR+list_of_origs[i])\n","\n","        num = 1\n","        for j in range(len(saved_bb_x_half)):\n","            crop_half = orig_img_clean_half[saved_bb_y_half[j]:saved_bb_y_half[j]+saved_bb_y_height_half[j], saved_bb_x_half[j]:saved_bb_x_half[j]+saved_bb_x_width_half[j]]\n","            crop_name_half = f'crop_{num}.png'\n","            cv2.imwrite(cropped_results_dir_half + crop_name_half, crop_half)\n","            num += 1\n","            # Write out info about found centroids\n","\n","\n","    with open(results_dir + 'Centroids_coords.txt', 'w') as f:\n","        f.write('Cordinates of found bounding boxes of cardiomyocytes of interest are:\\n')\n","        f.write('\\nHorizontal coordinates of upper left corner:')\n","        f.write(str(saved_bb_x))\n","        f.write('\\nVertical coordinates of upper left corners:')\n","        f.write(str(saved_bb_y))\n","        f.write('\\nWidths:')\n","        f.write(str(saved_bb_x_width))\n","        f.write('\\nHeight:')\n","        f.write(str(saved_bb_y_height))"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Ze1U_-Ja541i","executionInfo":{"status":"ok","timestamp":1646923890297,"user_tz":-60,"elapsed":1861,"user":{"displayName":"Filip Kadlec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03444318018645607943"}}},"outputs":[],"source":["# CLEANUP \n","shutil.rmtree(predictions_dir)\n","shutil.rmtree(cut_images_dir)\n","os.remove(temp_bin_pred_img)\n","if OUTPUT_HALFCOLLAPSED_CARD:\n","    os.remove(temp_bin_pred_img_half)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"FinalSeg.ipynb","provenance":[],"mount_file_id":"1uhJzNz5e11pnQSBrqYMPWDkInOKSy3dv","authorship_tag":"ABX9TyOrpI8OLzYGTlEy89d2AYZo"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}