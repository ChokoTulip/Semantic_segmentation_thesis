{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TrainMe.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNW0m92tK2ONFFnaCQKsZgU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["####################################################\n","# Variables in this cell shall be assigned by user #\n","####################################################\n","\n","# MODEL - name of the neural network architecture to be used\n","#       - Segnet or Xunet\n","# OUTPUT_DIR  - folder, where weights of trained model shall be saved \n","# DATASET_DIR - folder, where 'images' and 'masks' folder of the dataset may be found\n","# WEIGHTS     - file with path containing pre-trained weights of neural network\n","# BATCHSIZE   - depending on GPU and RAM\n","# USE_AUG     - if augmentation of data should be used, set to True\n","\n","OUTPUT_DIR = ''\n","DATASET_DIR = ''\n","TRAIN_FROM_SCRATCH = True  # True or False\n","WEIGHTS = ''               # if TRAIN_FROM_CRATCH is False\n","MODEL = 'Segnet'           # Segnet or Xunet\n","BATCHSIZE = 4              # Default 4, integer\n","USE_AUG = False            # True or False"],"metadata":{"id":"wEKntJrlX2NZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bymLdwJYWF1L"},"outputs":[],"source":["import os\n","import time\n","import glob\n","import cv2\n","import numpy as np\n","import random\n","import imageio\n","import tensorflow.keras\n","import tensorflow as tf\n","\n","import imgaug as ia\n","import imgaug.augmenters as iaa\n","from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n","\n","from tensorflow.keras.utils import to_categorical\n","from keras.metrics import MeanIoU\n","\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","from tensorflow.keras.utils import normalize\n","from keras.models import Model\n","from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, \\\n","    Dropout, Lambda, LeakyReLU, Add, ZeroPadding2D\n","\n","# Information about size of images, color channels and number of classes to be segmented\n","n_classes = 4\n","IMG_HEIGHT = 512\n","IMG_WIDTH = 512\n","IMG_CHANNELS = 1"]},{"cell_type":"code","source":["def get_model():\n","    if MODEL is 'Segnet':\n","        return Segnet()\n","    elif MODEL is 'Xunet':\n","        return Unet_Xception_ResNetBlock()\n","    else:\n","        return Segnet()\n","\n","def Segnet(nClasses=4, input_height=512, input_width=512):\n","    inputs = Input(shape=(input_height, input_width, 1))\n","    #Encoder\n","    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n","    conv1 = BatchNormalization()(conv1)\n","    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n","    conv1 = BatchNormalization()(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n","    conv2 = BatchNormalization()(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n","    conv3 = BatchNormalization()(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n","    conv4 = BatchNormalization()(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","    # Decoder\n","    up7 = UpSampling2D(size=(2, 2))(pool4)\n","    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same')(up7)\n","    conv7 = BatchNormalization()(conv7)\n","    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv7)\n","    conv7 = BatchNormalization()(conv7)\n","\n","    up8 = UpSampling2D(size=(2, 2))(conv7)\n","    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same')(up8)\n","    conv8 = BatchNormalization()(conv8)\n","    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv8)\n","    conv8 = BatchNormalization()(conv8)\n","\n","    up9 = UpSampling2D(size=(2, 2))(conv8)\n","    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same')(up9)\n","    conv9 = BatchNormalization()(conv9)\n","    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv9)\n","    conv9 = BatchNormalization()(conv9)\n","\n","    up10 = UpSampling2D(size=(2, 2))(conv9)\n","    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same')(up10)\n","    conv10 = BatchNormalization()(conv10)\n","    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv10)\n","    conv10 = BatchNormalization()(conv10)\n","\n","    outputs = Conv2D(nClasses, (1, 1), padding='same', activation='softmax')(conv10)\n","\n","    model = Model(inputs, outputs)\n","    \n","    return model\n","\n","from keras.applications.xception import Xception\n","\n","def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n","    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n","    x = BatchNormalization()(x)\n","    if activation == True:\n","        x = LeakyReLU(alpha=0.1)(x)\n","    return x\n","\n","def residual_block(blockInput, num_filters=16):\n","    x = LeakyReLU(alpha=0.1)(blockInput)\n","    x = BatchNormalization()(x)\n","    blockInput = BatchNormalization()(blockInput)\n","    x = convolution_block(x, num_filters, (3,3) )\n","    x = convolution_block(x, num_filters, (3,3), activation=False)\n","    x = Add()([x, blockInput])\n","    return x\n","\n","\n","def Unet_Xception_ResNetBlock(nClasses=4, input_height=512, input_width=512):\n","    \n","    backbone = Xception(input_shape=(input_height, input_width, 1), weights=None, include_top=False)\n","    \n","    inputs = backbone.input\n","\n","    conv4 = backbone.layers[121].output\n","    conv4 = LeakyReLU(alpha=0.1)(conv4)\n","    pool4 = MaxPooling2D((2, 2))(conv4)\n","    pool4 = Dropout(0.1)(pool4)\n","    \n","    convm = Conv2D(16*32, (3, 3), activation=None, padding=\"same\")(pool4)\n","    convm = residual_block(convm, 16*32)\n","    convm = residual_block(convm, 16*32)\n","    convm = LeakyReLU(alpha=0.1)(convm)\n","    \n","    deconv4 = Conv2DTranspose(16*16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n","    uconv4 = concatenate([deconv4, conv4])\n","    uconv4 = Dropout(0.1)(uconv4)\n","    \n","    uconv4 = Conv2D(16*16, (3, 3), activation=None, padding=\"same\")(uconv4)\n","    uconv4 = residual_block(uconv4, 16 * 16)\n","    uconv4 = residual_block(uconv4, 16*16)\n","    uconv4 = LeakyReLU(alpha=0.1)(uconv4)\n","    \n","    deconv3 = Conv2DTranspose(16*8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n","    conv3 = backbone.layers[31].output\n","    uconv3 = concatenate([deconv3, conv3])    \n","    uconv3 = Dropout(0.1)(uconv3)\n","    \n","    uconv3 = Conv2D(16*8, (3, 3), activation=None, padding=\"same\")(uconv3)\n","    uconv3 = residual_block(uconv3, 16*8)\n","    uconv3 = residual_block(uconv3, 16*8)\n","    uconv3 = LeakyReLU(alpha=0.1)(uconv3)\n","\n","    deconv2 = Conv2DTranspose(16*4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n","    conv2 = backbone.layers[21].output\n","    conv2 = ZeroPadding2D(((1,0),(1,0)))(conv2)\n","    uconv2 = concatenate([deconv2, conv2])\n","        \n","    uconv2 = Dropout(0.1)(uconv2)\n","    uconv2 = Conv2D(16*4, (3, 3), activation=None, padding=\"same\")(uconv2)\n","    uconv2 = residual_block(uconv2, 16*4)\n","    uconv2 = residual_block(uconv2, 16*4)\n","    uconv2 = LeakyReLU(alpha=0.1)(uconv2)\n","    \n","    deconv1 = Conv2DTranspose(16*2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n","    conv1 = backbone.layers[11].output\n","    conv1 = ZeroPadding2D(((3,0),(3,0)))(conv1)\n","    uconv1 = concatenate([deconv1, conv1])\n","    \n","    uconv1 = Dropout(0.1)(uconv1)\n","    uconv1 = Conv2D(16*2, (3, 3), activation=None, padding=\"same\")(uconv1)\n","    uconv1 = residual_block(uconv1, 16*2)\n","    uconv1 = residual_block(uconv1, 16*2)\n","    uconv1 = LeakyReLU(alpha=0.1)(uconv1)\n","    \n","    uconv0 = Conv2DTranspose(16*1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n","    uconv0 = Dropout(0.1)(uconv0)\n","    uconv0 = Conv2D(16*1, (3, 3), activation=None, padding=\"same\")(uconv0)\n","    uconv0 = residual_block(uconv0, 16*1)\n","    uconv0 = residual_block(uconv0, 16*1)\n","    uconv0 = LeakyReLU(alpha=0.1)(uconv0)\n","    \n","    uconv0 = Dropout(0.1/2)(uconv0)\n","\n","    \n","    outputs = Conv2D(nClasses, (1, 1), padding='same', activation='softmax')(uconv0)\n","\n","    model = Model(inputs, outputs)\n","\n","    return model"],"metadata":{"id":"ml4Pzy9XXLBf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def img_generator(img_dir, label_dir, batch_size):\n","    list_images = os.listdir(img_dir)\n","    random.shuffle(list_images)  # Randomize the choice of batches\n","    ids_train_split = range(len(list_images))\n","\n","    ##############################################################\n","    sometimes7 = lambda aug: iaa.Sometimes(0.7, aug)\n","    sometimes2 = lambda aug: iaa.Sometimes(0.2, aug)\n","\n","    seq = iaa.Sequential([\n","        iaa.OneOf([\n","            sometimes2(iaa.CropAndPad(percent=(0, 0.2), pad_mode=\"constant\", pad_cval=160))\n","        ]),\n","\n","        sometimes7(iaa.Affine(rotate=(-180, 180), mode='constant', cval=160)),\n","        iaa.Fliplr(0.4),\n","        iaa.Flipud(0.4)\n","    ], random_order=True)\n","    ##############################################################\n","\n","\n","    while True:\n","        for start in range(0, len(ids_train_split), batch_size):\n","            x_batch = []\n","            y_batch = []\n","            end = min(start + batch_size, len(ids_train_split))\n","            ids_train_batch = ids_train_split[start:end]\n","            for id in ids_train_batch:\n","                img = cv2.imread(os.path.join(img_dir, list_images[id]), 0)\n","                mask = imageio.imread(os.path.join(label_dir, list_images[id].replace('jpg', 'png')))\n","\n","                ##############################################################\n","                segmap = SegmentationMapsOnImage(mask, shape=img.shape)\n","                images_aug_i, segmaps_aug_i = seq(image=img, segmentation_maps=segmap)\n","                segmaps_aug_i = segmaps_aug_i.get_arr()\n","                ##############################################################\n","\n","                x_batch.append(images_aug_i)\n","                y_batch.append(segmaps_aug_i)\n","\n","\n","            x_batch = np.array(x_batch, np.float32) / 255.\n","            y_batch = np.array(y_batch, np.float32)\n","\n","            x_batch = np.expand_dims(x_batch, axis=3)\n","            x_batch = normalize(x_batch, axis=1)\n","\n","            y_batch = np.expand_dims(y_batch, axis=3)\n","            y_batch = to_categorical(y_batch, num_classes=4)\n","    \n","            yield x_batch, y_batch\n","            \n","def img_generator_not_aug(img_dir, label_dir, batch_size):\n","    list_images = os.listdir(img_dir)\n","    random.shuffle(list_images)  # Randomize the choice of batches\n","    ids_train_split = range(len(list_images))\n","\n","\n","    while True:\n","        for start in range(0, len(ids_train_split), batch_size):\n","            x_batch = []\n","            y_batch = []\n","            end = min(start + batch_size, len(ids_train_split))\n","            ids_train_batch = ids_train_split[start:end]\n","            for id in ids_train_batch:\n","                img = cv2.imread(os.path.join(img_dir, list_images[id]), 0)\n","                mask = imageio.imread(os.path.join(label_dir, list_images[id].replace('jpg', 'png')))\n","\n","                x_batch.append(img)\n","                y_batch.append(mask)\n","\n","            x_batch = np.array(x_batch, np.float32) / 255.\n","            y_batch = np.array(y_batch, np.float32)\n","\n","            x_batch = np.expand_dims(x_batch, axis=3)\n","            x_batch = normalize(x_batch, axis=1)\n","\n","            y_batch = np.expand_dims(y_batch, axis=3)\n","            y_batch = to_categorical(y_batch, num_classes=4)\n","            \n","            yield x_batch, y_batch"],"metadata":{"id":"_2sahqmDXqXZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TRAINING OF THE NET\n","model = get_model()\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[tf.keras.metrics.MeanIoU(num_classes=4)])\n","\n","if TRAIN_FROM_SCRATCH is False:\n","    model.load_weights(WEIGHTS)\n","\n","batchsize = BATCHSIZE\n","\n","# generators for yielding batches of TRAIN and TEST data\n","img_traindir = DATASET_DIR + 'images/train//'\n","seg_traindir = DATASET_DIR + 'masks/train//'\n","\n","img_testdir = DATASET_DIR + 'images/test//'\n","seg_testdir = DATASET_DIR + 'masks/test//'\n","\n","if USE_AUG:\n","    train_generator = img_generator(img_traindir, seg_traindir, batchsize)\n","    test_generator = img_generator(img_testdir, seg_testdir, batchsize)\n","else:\n","    train_generator = img_generator_not_aug(img_traindir, seg_traindir, batchsize)\n","    test_generator = img_generator_not_aug(img_testdir, seg_testdir, batchsize)\n","\n","#TODO: modelname\n","callbacks = [\n","    ModelCheckpoint(OUTPUT_DIR + '_' + MODEL + '_.h5', verbose=1, save_best_only=True),\n","    EarlyStopping(patience=15, monitor='val_loss'),\n","]\n"],"metadata":{"id":"VV3niIEEXvKD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["numof_train_images = 0\n","numof_test_images = 0\n","\n","for f in os.listdir(DATASET_DIR + 'images/train//'):\n","    if os.path.isfile(f) and f.endswith(\".png\"):\n","        numof_train_images += 1\n","\n","for f in os.listdir(DATASET_DIR + 'images/test//'):\n","    if os.path.isfile(f) and f.endswith(\".png\"):\n","        numof_test_images += 1\n","\n","history = model.fit(train_generator,\n","                    verbose=1,\n","                    epochs=500,\n","                    callbacks=callbacks,\n","                    validation_data=test_generator,\n","                    steps_per_epoch=numof_train_images//batchsize,\n","                    validation_steps=numof_test_images//batchsize,\n","                    shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":134},"id":"MRnupog_Xy3o","executionInfo":{"status":"error","timestamp":1647011037811,"user_tz":-60,"elapsed":24,"user":{"displayName":"Filip Kadlec","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03444318018645607943"}},"outputId":"3c0df5b2-94a8-48fb-fbba-6c0724bf47a1"},"execution_count":1,"outputs":[{"output_type":"error","ename":"IndentationError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-2d77c7642479>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    history = model.fit(train_generator,\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"]}]}]}